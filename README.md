
## A Major Project On "Human-Computer Interaction using Neuromuscular Signals"

### ABSTRACT
Subvocal speech or internal articulation is a form of non-voiced speech that is voluntarily
spoken. It is generated alongside the micromovement of the articulatory muscles that is
imperceptible to others. However, the faint sEMG (surface Electromyography) signals
can still be detected and analyzed to predict the internally articulated speech. This
research project attempts to study this very phenomenon and its possible use case in
human computer interaction. By extracting sEMG signals from several of these
articulators and processing the extracted signals, prominent features of a particular
utterance can be isolated and can be used to train a machine learning model. After training
the model on several such utterances, accurate predictions of the utterances can be made
which can be further utilized to perform a predefined action on a remote computer. This
research also explores on improving traditional speech recognition models by possible
augmentation of both approaches.

### Team Members: Rabin Nepal, Rhimesh Lwagun, Sanjay Rijal, Upendra Subedi
