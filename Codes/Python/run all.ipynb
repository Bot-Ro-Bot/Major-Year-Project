{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMG WORD PREDICTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT NECESSARY MODULES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "mlp.rc(\"xtick\",labelsize=12)\n",
    "mlp.rc(\"ytick\",labelsize=12)\n",
    "mlp.rc(\"axes\",labelsize=14)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10,5]\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "\n",
    "from scipy import signal\n",
    "from scipy.stats import zscore\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import librosa\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.decomposition import FastICA\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "CURR_DIR = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAIN_DIR = os.path.join(CURR_DIR,\"..\",\"..\")\n",
    "DATA_DIR = os.path.join(MAIN_DIR,\"dataset\")\n",
    "FILE_DIR = os.path.join(MAIN_DIR,\"dataset\",\"pickle\")\n",
    "FIG_DIR = os.path.join(MAIN_DIR,\"figures\")\n",
    "os.makedirs(FIG_DIR,exist_ok=True)\n",
    "\n",
    "SPEAKER = [\"RL\",\"RN\",\"SR\",\"US\"]\n",
    "MODE = [\"mentally\",\"mouthed\"]\n",
    "WORDS = LABELS = [\"add\",\"call\",\"go\",\"later\",\"left\",\"reply\",\"right\",\"stop\",\"subtract\",\"you\"]\n",
    "\n",
    "SAMPLING_FREQ = 250 \n",
    "NUM_CHANNELS = 8\n",
    "\n",
    "\n",
    "# a function to save plotted figures\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(FIG_DIR, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['US_feature_spectral_me.pickle', 'US_feature_spectral_mo.pickle', 'US_feature_time_me.pickle', 'US_feature_time_mo.pickle', 'US_feature_time_spectral_me.pickle', 'US_feature_time_spectral_mo.pickle']\n"
     ]
    }
   ],
   "source": [
    "DATASET = os.listdir(FILE_DIR)\n",
    "DATASET.sort()\n",
    "print(DATASET[-6:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# feature_spectral_mental = pickle.load(open(os.path.join(FILE_DIR,DATASET[-6]),\"rb\"))\n",
    "# feature_spectral_mouthed = pickle.load(open(os.path.join(FILE_DIR,DATASET[-3]),\"rb\"))\n",
    "# feature_time_mental = pickle.load(open(os.path.join(FILE_DIR,DATASET[-4]),\"rb\"))\n",
    "feature_time_mouthed = pickle.load(open(os.path.join(FILE_DIR,DATASET[-3]),\"rb\"))\n",
    "# feature_time_spectral_mental = pickle.load(open(os.path.join(FILE_DIR,DATASET[4]),\"rb\"))\n",
    "# feature_time_spectral_mental = pickle.load(open(os.path.join(FILE_DIR,DATASET[5]),\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'label'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# feature_time_mental.keys()\n",
    "feature_time_mouthed.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_spectral = feature_spectral_mouthed[\"data\"]\n",
    "Y_spectral = feature_spectral_mouthed[\"label\"]\n",
    "\n",
    "X_time = feature_time_mouthed[\"data\"]\n",
    "Y_time = feature_time_mouthed[\"label\"]\n",
    "\n",
    "# X_spectral = feature_spectral_mental[\"data\"]\n",
    "# Y_spectral = feature_spectral_mental[\"label\"]\n",
    "\n",
    "# X_time = feature_time_mental[\"data\"]\n",
    "# Y_time = feature_time_mental[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1765, 920, 40)\n",
      "(1765,)\n",
      "(1765, 920, 40)\n",
      "(1765,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(X_spectral.shape)\n",
    "print(Y_spectral.shape)\n",
    "\n",
    "print(X_time.shape)\n",
    "print(Y_time.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LABEL ENCODING (MLP AND CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['add' 'call' 'go' 'later' 'left' 'reply' 'right' 'stop' 'subtract' 'you']\n",
      "Encoded labels (normal): \n",
      " [1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "Y = encoder.fit_transform(Y_spectral)\n",
    "# Y_1hot = tf.keras.utils.to_categorical(Y_spectral, num_classes = 10)\n",
    "print(encoder.classes_)\n",
    "print(\"Encoded labels (normal): \\n\",Y[0:5])\n",
    "# print(\"Encoded labels (ONE-HOT): \\n\",Y_1hot[0:5])\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# Y_time = encoder.fit_transform(Y_time)\n",
    "# Y_1hot_time = tf.keras.utils.to_categorical(Y_time, num_classes = 10)\n",
    "# print(encoder.classes_)\n",
    "# print(\"Encoded labels (normal): \\n\",Y_time[0:5])\n",
    "# print(\"Encoded labels (ONE-HOT): \\n\",Y_1hot_time[0:5])\n",
    "\n",
    "# encoder = LabelEncoder()\n",
    "# Y_spectral = encoder.fit_transform(Y_spectral)\n",
    "# Y_1hot_spectral = tf.keras.utils.to_categorical(Y_spectral, num_classes = 10)\n",
    "# print(encoder.classes_)\n",
    "# print(\"Encoded labels (normal): \\n\",Y_spectral[0:5])\n",
    "# print(\"Encoded labels (ONE-HOT): \\n\",Y_1hot_spectral[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X,Y):\n",
    "    split = StratifiedShuffleSplit(n_splits=1, test_size =0.1, random_state=42)\n",
    "    train_id, test_id = next(split.split(X,Y))\n",
    "    return np.array([X[n] for n in train_id]), np.array([Y[n] for n in train_id]), np.array([X[n] for n in test_id]),np.array([Y[n] for n in test_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCM(y, predictions,y2,predictions2,filename=\" \"):\n",
    "    cm = confusion_matrix(y, predictions)\n",
    "#     print(cm)\n",
    "#     plt.suptitle(\"KNN\\n\\n\")\n",
    "    plt.subplot(121)\n",
    "    plt.title(\"With Temporal Features\")\n",
    "    plt.imshow(confusion_matrix(y, predictions,normalize=\"true\"), interpolation = 'nearest',cmap = plt.cm.Reds)\n",
    "    plt.xticks(range(len(LABELS)), LABELS, rotation = 45)\n",
    "    plt.yticks(range(len(LABELS)), LABELS)\n",
    "    \n",
    "    plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "\n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            plt.text(j,i, cm[i][j],horizontalalignment='center',verticalalignment='center')\n",
    "   \n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.title(\"With Spectral Features\")\n",
    "    plt.imshow(confusion_matrix(y2, predictions2,normalize=\"true\"), interpolation = 'nearest',cmap = plt.cm.Reds)\n",
    "    plt.xticks(range(len(LABELS)), LABELS, rotation = 45)\n",
    "    plt.yticks(range(len(LABELS)), LABELS)\n",
    "    \n",
    "#     plt.ylabel('Actual Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    cm = confusion_matrix(y2, predictions2)\n",
    "    \n",
    "    for i in range(10):\n",
    "        for j in range(10):\n",
    "            plt.text(j,i, cm[i][j],horizontalalignment='center',verticalalignment='center')\n",
    "    \n",
    "    if(filename!=\" \"):\n",
    "        save_fig(filename)\n",
    "    plt.subplots_adjust(wspace=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_fold_CV(X_new,Y_new,K=10):\n",
    "    kfold = StratifiedKFold(n_splits=K,random_state=42)\n",
    "    acc = []\n",
    "    for train_id,test_id in kfold.split(X_new,Y_new):\n",
    "        #acc.append(KNN_Classifier(X_new[train_id],Y_new[train_id],X_new[test_id],Y_new[test_id]))\n",
    "        acc.append(MLP_Classifier(X_new[train_id],Y_new[train_id],X_new[test_id],Y_new[test_id]))\n",
    "        #acc.append(CNN_Classifier(X_new[train_id],Y_new[train_id],X_new[test_id],Y_new[test_id]))\n",
    "    return np.array(acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K fold\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FLATTEN DATA FOR MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw feature shape:  (1765, 36800)\n",
      "Raw feature shape:  (1765, 36800)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_MLP_time = np.array([x.flatten() for x in X_time])\n",
    "print(\"Raw feature shape: \",X_MLP_time.shape)\n",
    "\n",
    "\n",
    "X_MLP_spectral = np.array([x.flatten() for x in X_spectral])\n",
    "print(\"Raw feature shape: \",X_MLP_spectral.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_MLP_time = scalar.fit_transform(X_MLP_time,Y)\n",
    "X_MLP_spectral = scalar.fit_transform(X_MLP_spectral,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = FastICA(n_components=100,random_state=42)\n",
    "X_MLP_time = reducer.fit_transform(X_MLP_time)\n",
    "X_MLP_spectral = reducer.fit_transform(X_MLP_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_time,Y_train_time,X_test_time,Y_test_time = train_test_split(X_MLP_time,Y)\n",
    "\n",
    "# print(\"Train Set Shape of X: \",X_train_time.shape)\n",
    "# print(\"Test Set Shape of X: \",X_test_time.shape)\n",
    "\n",
    "# print(\"Train Set Shape of Y: \",Y_train_time.shape)\n",
    "# print(\"Test Set Shape of Y: \",Y_test_time.shape)\n",
    "\n",
    "\n",
    "# X_train_spectral,Y_train_spectral,X_test_spectral,Y_test_spectral = train_test_split(X_MLP_spectral,Y)\n",
    "\n",
    "# print(\"Train Set Shape of X: \",X_train_spectral.shape)\n",
    "# print(\"Test Set Shape of X: \",X_test_spectral.shape)\n",
    "\n",
    "# print(\"Train Set Shape of Y: \",Y_train_spectral.shape)\n",
    "# print(\"Test Set Shape of Y: \",Y_test_spectral.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEFINE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP_Classifier(X_train,Y_train,X_test,Y_test,PLOTS=True):\n",
    "    MLP_model = keras.Sequential()\n",
    "    MLP_model.add(keras.layers.Dense(units=200,activation=\"relu\",input_shape=X_train[0].shape))\n",
    "    MLP_model.add(keras.layers.Dropout(0.5))\n",
    "    MLP_model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "    MLP_model.add(keras.layers.Dense(64,activation=\"relu\"))\n",
    "    MLP_model.add(keras.layers.Dropout(0.5))\n",
    "    MLP_model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "    print(MLP_model.summary())\n",
    "    optimizer=keras.optimizers.Adam()\n",
    "    MLP_model.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\n",
    "    history = MLP_model.fit(X_train,Y_train,epochs=30,validation_data=(X_test,Y_test),verbose=1)    \n",
    "    MLP_prediction = np.array(list(map(np.argmax,MLP_model.predict(X_test))))\n",
    "    \n",
    "#     if(PLOTS==True):\n",
    "#         plt.plot(history.history[\"accuracy\"],\"r:\")\n",
    "#         plt.plot(history.history[\"loss\"],\"b--\")\n",
    "#         plt.xlabel(\"Epoch\")\n",
    "#         plt.ylabel(\"Accuracy/ Loss\")\n",
    "#         plt.legend([\"Accuracy\",\"Loss\"])\n",
    "    # save_fig(\"ACC_LOSS_US_FIltered\")\n",
    "\n",
    "    return Y_test,MLP_prediction,history.history['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(177,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #K_fold_CV(X_new,Y_new,K=10)\n",
    "\n",
    "# a = K_fold_CV(X_time,Y_time)\n",
    "# a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a,b,MLP_history_time = MLP_Classifier(X_train_time,Y_train_time,X_test_time,Y_test_time)\n",
    "c,d,MLP_history_spectral = MLP_Classifier(X_train_spectral,Y_train_spectral,X_test_spectral,Y_test_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(MLP_history_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCM(a,b.flatten(),c,d.flatten(),\"US_mental_MLP\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "# plt.title(\"With Temporal Features\")\n",
    "plt.plot(MLP_history_time.history[\"loss\"],\"b:\")\n",
    "plt.plot(MLP_history_spectral.history[\"loss\"],\"r--\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\"Temporal\",\"Spectral\"])\n",
    "\n",
    "plt.subplot(122)\n",
    "# plt.title(\"With Temporal Features\")\n",
    "plt.plot(MLP_history_time.history[\"accuracy\"],\"b:\")\n",
    "plt.plot(MLP_history_spectral.history[\"accuracy\"],\"r--\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.legend([\"Temporal\",\"Spectral\"])\n",
    "save_fig(\"US_mental_MLP_ACCURACY_LOSS\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision/Recall with Temporal Features\")\n",
    "print(classification_report(a,b))\n",
    "\n",
    "print(\"Precision/Recall with Spectral Features\")\n",
    "print(classification_report(c,d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN MODEL DEVELOPMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "X_CNN_spectral = deepcopy(X_spectral)\n",
    "\n",
    "X_CNN_time = deepcopy(X_time)\n",
    "\n",
    "print(X_CNN_time.shape)\n",
    "\n",
    "print(X_CNN_spectral.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCALING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = StandardScaler()\n",
    "X_CNN_time = (scalar.fit_transform(X_CNN_time.reshape(X_CNN_time.shape[0],-1),Y)).reshape(X_CNN_time.shape[0],X_CNN_time.shape[1],-1)\n",
    "X_CNN_spectral = (scalar.fit_transform(X_CNN_spectral.reshape(X_CNN_time.shape[0],-1),Y)).reshape(X_CNN_time.shape[0],X_CNN_time.shape[1],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(X_CNN_time.shape)\n",
    "\n",
    "print(X_CNN_spectral.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_time,Y_train_time,X_test_time,Y_test_time = train_test_split(X_CNN_time,Y)\n",
    "print(\"Train Set Shape: \",X_train_time.shape)\n",
    "print(\"Test Set Shape: \",X_test_time.shape)\n",
    "\n",
    "print(\"Train Set Shape: \",Y_train_time.shape)\n",
    "print(\"Test Set Shape: \",Y_test_time.shape)\n",
    "\n",
    "\n",
    "X_train_spectral,Y_train_spectral,X_test_spectral,Y_test_spectral = train_test_split(X_CNN_spectral,Y)\n",
    "print(\"Train Set Shape: \",X_train_spectral.shape)\n",
    "print(\"Test Set Shape: \",X_test_spectral.shape)\n",
    "\n",
    "print(\"Train Set Shape: \",Y_train_spectral.shape)\n",
    "print(\"Test Set Shape: \",Y_test_spectral.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_spectral = (Y_train_spectral.reshape(-1,len(Y_train_spectral))).T\n",
    "Y_test_spectral = (Y_test_spectral.reshape(-1,len(Y_test_spectral))).T\n",
    "\n",
    "print(\"Train Set Shape: \",X_train_spectral.shape)\n",
    "print(\"Test Set Shape: \",X_test_spectral.shape)\n",
    "\n",
    "print(\"Train Set Shape: \",Y_train_spectral.shape)\n",
    "print(\"Test Set Shape: \",Y_test_spectral.shape)\n",
    "\n",
    "\n",
    "Y_train_time = (Y_train_time.reshape(-1,len(Y_train_time))).T\n",
    "Y_test_time = (Y_test_time.reshape(-1,len(Y_test_time))).T\n",
    "\n",
    "# print(\"Train Set Shape: \",X_train_spectral.shape)\n",
    "# print(\"Test Set Shape: \",X_test_spectral.shape)\n",
    "\n",
    "# print(\"Train Set Shape: \",Y_train_spectral.shape)\n",
    "# print(\"Test Set Shape: \",Y_test_spectral.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CNN_Classifier(X_train,Y_train,X_test,Y_test,PLOTS=False):\n",
    "    n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
    "    CNN_model = keras.Sequential()\n",
    "    CNN_model.add(keras.layers.Conv1D(100, kernel_size = 12, input_shape =(n_timesteps,n_features), activation = \"relu\"))\n",
    "    # \tCNN_model.add(keras.layers.Conv1D(100, kernel_size = 12, input_shape = X_train.shape[1:], activation = \"relu\"))\n",
    "    CNN_model.add(keras.layers.MaxPool1D(pool_size=2))\n",
    "    CNN_model.add(keras.layers.Conv1D(100,kernel_size=6,activation=\"relu\"))\n",
    "    CNN_model.add(keras.layers.MaxPool1D(pool_size=2))\n",
    "    CNN_model.add(keras.layers.Flatten())\n",
    "    CNN_model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "    CNN_model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "    opt = keras.optimizers.Adam()\n",
    "\n",
    "    CNN_model.compile(optimizer = opt, loss = keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "    print(CNN_model.summary())\n",
    "    history = CNN_model.fit(X_train, Y_train, epochs = 10, batch_size = 50, validation_data =(X_test, Y_test) ,verbose = 1)\n",
    "    CNN_prediction = np.array(list(map(np.argmax,CNN_model.predict(X_test))))\n",
    "    return Y_test,CNN_prediction,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "e,f,history_time = CNN_Classifier(X_train_time,Y_train_time,X_test_time,Y_test_time)\n",
    "g,h, history_spectral = CNN_Classifier(X_train_spectral,Y_train_spectral,X_test_spectral,Y_test_spectral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCM(e,f.flatten(),g,h.flatten(),\"US_CNN_mental_10_epoch\")\n",
    "# print(b.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.subplot(121)\n",
    "# plt.title(\"With Temporal Features\")\n",
    "plt.plot(history_time.history[\"loss\"],\"b:\")\n",
    "plt.plot(history_spectral.history[\"loss\"],\"r--\")\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend([\"Temporal\",\"Spectral\"])\n",
    "\n",
    "plt.subplot(122)\n",
    "# plt.title(\"With Temporal Features\")\n",
    "plt.plot(history_time.history[\"accuracy\"],\"b:\")\n",
    "plt.plot(history_spectral.history[\"accuracy\"],\"r--\")\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.subplots_adjust(wspace=0.3)\n",
    "plt.legend([\"Temporal\",\"Spectral\"])\n",
    "save_fig(\"US_mental_CNN_ACCURACY_LOSS_10_epoch\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Precision/Recall with Temporal Features\")\n",
    "print(classification_report(e,f))\n",
    "\n",
    "print(\"Precision/Recall with Spectral Features\")\n",
    "print(classification_report(g,h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(X_time)\n",
    "\n",
    "# #reshaping for 2d cnn\n",
    "# XX_time = np.zeros((X_time.shape[0], X_time.shape[1], int(X_time.shape[-1]/8), 8))\n",
    "# YY_time = Y_time\n",
    "\n",
    "\n",
    "\n",
    "# for i in range(len(XX_time)):\n",
    "#     for chan in range(XX_time.shape[-1]):\n",
    "#         for feat in range(XX_time.shape[-2]):\n",
    "#             XX_time[i, :, feat, chan] = X_time[i, :, XX_time.shape[-2]*chan + feat ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def CNN_Classifier_2D(X_train,Y_train,X_test,Y_test,PLOTS=False):\n",
    "#     Y_train = tf.keras.utils.to_categorical(Y_train, num_classes = 10)\n",
    "#     Y_test = tf.keras.utils.to_categorical(Y_test, num_classes = 10)\n",
    "    \n",
    "# #     n_timesteps, n_features, n_outputs = X_train.shape[1], X_train.shape[2], Y_train.shape[1]\n",
    "#     CNN_model = keras.Sequential()\n",
    "# #     CNN_model.add(keras.layers.Conv2D(100, kernel_size = 12, input_shape =(n_timesteps,n_features), activation = \"relu\"))\n",
    "#     CNN_model.add(keras.layers.Conv2D(100, kernel_size = (5,5), input_shape = X_train.shape[1:], activation = \"relu\"))\n",
    "#     CNN_model.add(keras.layers.MaxPool2D(pool_size=(1, 1)))\n",
    "#     CNN_model.add(keras.layers.Conv2D(100,kernel_size= (6,1),activation=\"relu\"))\n",
    "#     CNN_model.add(keras.layers.MaxPool2D(pool_size= (1, 1) ))\n",
    "#     CNN_model.add(keras.layers.Flatten())\n",
    "#     CNN_model.add(keras.layers.Dense(100,activation=\"relu\"))\n",
    "#     CNN_model.add(keras.layers.Dense(10,activation=\"softmax\"))\n",
    "\n",
    "#     opt = keras.optimizers.Adam()\n",
    "\n",
    "#     CNN_model.compile(optimizer = opt, loss = keras.losses.sparse_categorical_crossentropy, metrics=['accuracy'])\n",
    "#     print(CNN_model.summary())\n",
    "#     history = CNN_model.fit(X_train, Y_train, epochs = 30, batch_size = 50, validation_data =(X_test, Y_test) ,verbose = 1)\n",
    "#     CNN_prediction = np.array(list(map(np.argmax,CNN_model.predict(X_test))))\n",
    "    \n",
    "# #     if(PLOTS=True):\n",
    "# #         plt.plot(history.history[\"accuracy\"],\"r:\")\n",
    "# #         plt.plot(history.history[\"loss\"],\"b--\")\n",
    "# #         plt.xlabel(\"Epoch\")\n",
    "# #         plt.ylabel(\"Accuracy/ Loss\")\n",
    "# #         plt.legend([\"Accuracy\",\"Loss\"])\n",
    "# #         # save_fig(\"ACC_LOSS_US_FIltered\")\n",
    "    \n",
    "    \n",
    "#     return Y_test,CNN_prediction,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_time,Y_train_time,X_test_time,Y_test_time = train_test_split(XX_time,Y_en)\n",
    "# a,b,history_time = CNN_Classifier_2D(X_train_time,Y_train_time,X_test_time,Y_test_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
